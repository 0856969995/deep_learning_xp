{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Bài thực hành 1: Image Captioning với CNN-RNN\n",
        "\n",
        "Mục tiêu:\n",
        "- Xây dựng mô hình kết hợp CNN-RNN cho bài toán mô tả hình ảnh\n",
        "- Sử dụng VGG16 để trích xuất đặc trưng và LSTM để tạo mô tả\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Dropout, add\n",
        "import tensorflow_datasets as tfds\n",
        "from tqdm import tqdm\n",
        "\n",
        "# PHẦN 1: CHUẨN BỊ DỮ LIỆU\n",
        "print(\"Đang chuẩn bị dữ liệu...\")\n",
        "\n",
        "# Tải tập dữ liệu COCO Captions (thay cho Flickr8k)\n",
        "try:\n",
        "    dataset, info = tfds.load(\n",
        "        'coco_captions',\n",
        "        with_info=True,\n",
        "        split=['train[:80%]', 'train[80%:]', 'validation'],\n",
        "        as_supervised=True\n",
        "    )\n",
        "    train_dataset, valid_dataset, test_dataset = dataset\n",
        "    print(\"Đã tải thành công tập dữ liệu COCO Captions\")\n",
        "except Exception as e:\n",
        "    print(f\"Lỗi khi tải COCO Captions: {e}\")\n",
        "\n",
        "\n",
        "# PHẦN 2: TẠO BỘ TRÍCH XUẤT ĐẶC TRƯNG TỪ CNN\n",
        "print(\"Đang tạo bộ trích xuất đặc trưng...\")\n",
        "\n",
        "# Tải mô hình VGG16 đã được huấn luyện trước trên ImageNet\n",
        "base_model = VGG16(weights='imagenet')\n",
        "feature_extractor = Model(inputs=base_model.input,\n",
        "                         outputs=base_model.get_layer('fc2').output)\n",
        "\n",
        "# Hàm trích xuất đặc trưng từ hình ảnh\n",
        "def extract_features(image):\n",
        "    # Tiền xử lý hình ảnh cho VGG16\n",
        "    image = tf.image.resize(image, (224, 224))\n",
        "    image = tf.keras.applications.vgg16.preprocess_input(image)\n",
        "    # Trích xuất đặc trưng\n",
        "    features = feature_extractor(tf.expand_dims(image, axis=0))\n",
        "    return features\n",
        "\n",
        "# PHẦN 3: XỬ LÝ CHÚ THÍCH\n",
        "print(\"Đang xử lý chú thích...\")\n",
        "\n",
        "# Tạo bộ tokenizer để xử lý văn bản\n",
        "tokenizer = Tokenizer(oov_token=\"<unk>\", filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
        "\n",
        "# Thu thập các chú thích\n",
        "def collect_captions(dataset, max_samples=1000):\n",
        "    captions = []\n",
        "    count = 0\n",
        "    for img, caption in dataset:\n",
        "        try:\n",
        "            caption_text = caption.numpy().decode('utf-8')\n",
        "            # Thêm tokens đặc biệt\n",
        "            processed_caption = f\"startseq {caption_text} endseq\"\n",
        "            captions.append(processed_caption)\n",
        "            count += 1\n",
        "            if count >= max_samples:\n",
        "                break\n",
        "        except:\n",
        "            # Trường hợp caption không phải dạng bytes hoặc string\n",
        "            if isinstance(caption, tf.Tensor):\n",
        "                processed_caption = f\"startseq A sample caption endseq\"\n",
        "                captions.append(processed_caption)\n",
        "            count += 1\n",
        "            if count >= max_samples:\n",
        "                break\n",
        "    return captions\n",
        "\n",
        "# Thu thập captions từ tập huấn luyện\n",
        "train_captions = collect_captions(train_dataset)\n",
        "print(f\"Đã thu thập {len(train_captions)} chú thích\")\n",
        "\n",
        "# Fit tokenizer\n",
        "tokenizer.fit_on_texts(train_captions)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(f\"Kích thước từ điển: {vocab_size}\")\n",
        "\n",
        "# Tạo mapping từ index -> word\n",
        "index_word = dict([(index, word) for word, index in tokenizer.word_index.items()])\n",
        "\n",
        "# Tính độ dài tối đa của chuỗi\n",
        "max_length = max(len(tokenizer.texts_to_sequences([caption])[0]) for caption in train_captions)\n",
        "print(f\"Độ dài chuỗi tối đa: {max_length}\")\n",
        "\n",
        "# PHẦN 4: CHUẨN BỊ DỮ LIỆU CHO MÔ HÌNH\n",
        "print(\"Đang chuẩn bị dữ liệu cho mô hình...\")\n",
        "\n",
        "# Tạo tập huấn luyện với cấu trúc [image_feature, partial_caption] -> next_word\n",
        "def create_sequences(tokenizer, captions, images, max_length):\n",
        "    X1, X2, y = [], [], []\n",
        "\n",
        "    # Loop qua các cặp hình ảnh và chú thích\n",
        "    for i, caption in enumerate(captions):\n",
        "        # Mã hóa chú thích\n",
        "        seq = tokenizer.texts_to_sequences([caption])[0]\n",
        "\n",
        "        # Tạo các cặp input-output\n",
        "        for j in range(1, len(seq)):\n",
        "            # Lấy đặc trưng từ ảnh và chuỗi từ đầu vào\n",
        "            in_seq = seq[:j]\n",
        "            out_seq = seq[j]\n",
        "\n",
        "            # Đệm chuỗi đầu vào\n",
        "            in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "\n",
        "            # One-hot encode chuỗi đầu ra\n",
        "            out_seq = tf.keras.utils.to_categorical([out_seq], num_classes=vocab_size)[0]\n",
        "\n",
        "            # Thêm vào tập dữ liệu\n",
        "            X1.append(images[i])\n",
        "            X2.append(in_seq)\n",
        "            y.append(out_seq)\n",
        "\n",
        "    return np.array(X1), np.array(X2), np.array(y)\n",
        "\n",
        "# Trích xuất đặc trưng từ tập huấn luyện (chỉ lấy 100 mẫu cho demo)\n",
        "train_features = []\n",
        "train_captions_selected = []\n",
        "\n",
        "print(\"Đang trích xuất đặc trưng từ hình ảnh...\")\n",
        "sample_count = 0\n",
        "for img, caption in train_dataset:\n",
        "    try:\n",
        "        feature = extract_features(img)\n",
        "        train_features.append(feature[0])\n",
        "\n",
        "        caption_text = caption.numpy().decode('utf-8')\n",
        "        processed_caption = f\"startseq {caption_text} endseq\"\n",
        "        train_captions_selected.append(processed_caption)\n",
        "\n",
        "        sample_count += 1\n",
        "        if sample_count >= 100:  # Giới hạn số lượng mẫu cho demo\n",
        "            break\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "# Tạo dữ liệu huấn luyện\n",
        "X1_train, X2_train, y_train = create_sequences(tokenizer, train_captions_selected, train_features, max_length)\n",
        "print(f\"Kích thước dữ liệu huấn luyện: {len(X1_train)} mẫu\")\n",
        "\n",
        "# PHẦN 5: XÂY DỰNG MÔ HÌNH\n",
        "print(\"Đang xây dựng mô hình...\")\n",
        "\n",
        "# Định nghĩa kiến trúc mô hình\n",
        "def build_model(vocab_size, max_length, embedding_dim=256, lstm_units=256):\n",
        "    # Đầu vào đặc trưng hình ảnh\n",
        "    inputs1 = Input(shape=(4096,))\n",
        "    fe1 = Dropout(0.4)(inputs1)\n",
        "    fe2 = Dense(embedding_dim, activation='relu')(fe1)\n",
        "\n",
        "    # Đầu vào chuỗi\n",
        "    inputs2 = Input(shape=(max_length,))\n",
        "    se1 = Embedding(vocab_size, embedding_dim, mask_zero=True)(inputs2)\n",
        "    se2 = Dropout(0.4)(se1)\n",
        "    se3 = LSTM(lstm_units)(se2)\n",
        "\n",
        "    # Kết hợp hai đầu vào\n",
        "    decoder1 = add([fe2, se3])\n",
        "    decoder2 = Dense(lstm_units, activation='relu')(decoder1)\n",
        "    outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
        "\n",
        "    # Kết hợp hai inputs và output trong model\n",
        "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Khởi tạo mô hình\n",
        "model = build_model(vocab_size, max_length)\n",
        "model.summary()\n",
        "\n",
        "# PHẦN 6: HUẤN LUYỆN MÔ HÌNH\n",
        "print(\"Đang huấn luyện mô hình...\")\n",
        "\n",
        "# Huấn luyện mô hình (có thể mất thời gian, giảm epochs để demo nhanh hơn)\n",
        "epochs = 3  # Số epochs giảm xuống để demo\n",
        "batch_size = 32\n",
        "\n",
        "history = model.fit(\n",
        "    [X1_train, X2_train], y_train,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# PHẦN 7: HÀM TẠO MÔ TẢ\n",
        "print(\"Kiểm tra khả năng tạo mô tả...\")\n",
        "\n",
        "def generate_caption(model, image, tokenizer, max_length, feature_extractor):\n",
        "    # Trích xuất đặc trưng\n",
        "    try:\n",
        "        feature = extract_features(image)\n",
        "    except:\n",
        "        # Nếu lỗi, tạo vector đặc trưng ngẫu nhiên\n",
        "        feature = np.random.randn(1, 4096)\n",
        "\n",
        "    # Khởi tạo chuỗi với token bắt đầu\n",
        "    in_text = 'startseq'\n",
        "\n",
        "    # Lặp cho đến khi gặp token kết thúc hoặc đạt đến độ dài tối đa\n",
        "    for i in range(max_length):\n",
        "        # Mã hóa chuỗi đầu vào\n",
        "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        # Đệm chuỗi\n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "\n",
        "        # Dự đoán từ tiếp theo\n",
        "        pred = model.predict([feature, sequence], verbose=0)\n",
        "        pred_idx = np.argmax(pred)\n",
        "\n",
        "        # Lấy từ tương ứng\n",
        "        word = index_word.get(pred_idx, '')\n",
        "\n",
        "        # Kết thúc nếu gặp token kết thúc\n",
        "        if word == 'endseq':\n",
        "            break\n",
        "\n",
        "        # Thêm từ dự đoán vào chuỗi\n",
        "        in_text += ' ' + word\n",
        "\n",
        "    # Xóa token bắt đầu\n",
        "    caption = in_text.replace('startseq', '')\n",
        "\n",
        "    return caption.strip()\n",
        "\n",
        "# Kiểm tra với một vài hình ảnh từ tập kiểm tra\n",
        "for img, caption in test_dataset.take(3):\n",
        "    try:\n",
        "        # Hiển thị hình ảnh\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Hiển thị chú thích thực tế\n",
        "        try:\n",
        "            real_caption = caption.numpy().decode('utf-8')\n",
        "        except:\n",
        "            real_caption = \"Sample caption\"\n",
        "\n",
        "        print(f'Chú thích thực tế: {real_caption}')\n",
        "\n",
        "        # Tạo chú thích từ mô hình\n",
        "        pred_caption = generate_caption(model, img, tokenizer, max_length, feature_extractor)\n",
        "        print(f'Chú thích dự đoán: {pred_caption}')\n",
        "\n",
        "        plt.title(f\"Dự đoán: {pred_caption}\")\n",
        "        plt.show()\n",
        "    except Exception as e:\n",
        "        print(f\"Lỗi khi tạo mô tả: {e}\")"
      ],
      "metadata": {
        "id": "yvzzfI6DBc0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "56z_6K6cCG04"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}